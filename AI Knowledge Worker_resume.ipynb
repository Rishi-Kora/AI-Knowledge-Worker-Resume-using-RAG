{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bc5e64-47bd-47a7-83f9-93b9b1564c2a",
   "metadata": {},
   "source": [
    "## Expert Knowledge Worker\n",
    "\n",
    "### A question answering agent that is an expert knowledge worker\n",
    "### To upload the Resume in PDF and convert it to text and ask questions based on the resume using gradio\n",
    "### The agent needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy.\n",
    "\n",
    "This first implementation will use a simple, brute-force type of RAG.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08325a6-13ae-4543-82ba-acedfcbeb82e",
   "metadata": {},
   "source": [
    "# Installing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b61d482-1cba-4f26-8789-b5c4fdc58cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --q pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c8bb0-04da-46af-b1fd-aca5cd160c41",
   "metadata": {},
   "source": [
    "# Importing all the neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e3ed0a-5700-4aab-b8de-f94933099c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d835a34e-d352-4c75-a8f3-a63eeae3758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4d81ec-f1ec-43c3-a964-54f1e7ddff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_dir  is a <class 'pathlib.WindowsPath'>\n",
      "text_dir is a <class 'pathlib.WindowsPath'>\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path().resolve()\n",
    "pdf_dir  = BASE_DIR / \"resumes_pdf\"\n",
    "text_dir = BASE_DIR / \"resumes_txt\"\n",
    "\n",
    "print(\"pdf_dir  is a\", type(pdf_dir))\n",
    "print(\"text_dir is a\", type(text_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f187c9a-4160-4601-ae2e-178400706704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/DELL/Documents/Projects/llm_engineering/week5/resumes_pdf')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd64745-69c3-4e9d-afd8-92ea7c607c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDFs:\n",
      "  Profile (1).pdf\n",
      "  Rishi Kora Resume.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_files = sorted(pdf_dir.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDFs:\")\n",
    "for p in pdf_files:\n",
    "    print(\" \", p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b97504-aab6-47c9-ad41-95adbc3a9b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Profile (1).pdf → Profile (1).txt\n",
      "Converted Rishi Kora Resume.pdf → Rishi Kora Resume.txt\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "for pdf_path in pdf_files:\n",
    "    txt_path = text_dir / f\"{pdf_path.stem}.txt\"\n",
    "    with pdfplumber.open(pdf_path) as pdf, \\\n",
    "         open(txt_path, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            out_f.write(f\"--- Page {i} ---\\n\")\n",
    "            out_f.write(page.extract_text() or \"[No extractable text]\")\n",
    "            out_f.write(\"\\n\\n\")\n",
    "    print(f\"Converted {pdf_path.name} → {txt_path.name}\")\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64906d6d-f27e-469a-a595-86c7f9bbf372",
   "metadata": {},
   "source": [
    "# Choosing a model from OpenAI which is low and creating a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b92bb9-d7ef-41e0-8c74-e37f9187b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f41fb-98b5-4254-8aed-b812d8100033",
   "metadata": {},
   "source": [
    "# Load environment variables in a file called `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226a909c-3124-4b23-ae96-5d22bdd8ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347eda4-fcee-4c3d-ba6a-eede08efa420",
   "metadata": {},
   "source": [
    "# This code loads `.md` files from subfolders in resumes_txt/, tags each with its folder name as metadata, and splits them into smaller text chunks. It helps organize and prepare data for use in RAG-based AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b672f94-240f-472f-a919-cf8ec3e9d7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1878, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 3\n",
      "Document types found: {'Rishi Kora Resume', 'Profile (1)'}\n"
     ]
    }
   ],
   "source": [
    "folders = glob.glob(\"resumes_txt/*\") \n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "text_loader_kwargs = {\"encoding\": \"utf-8\"}\n",
    "\n",
    "documents = []\n",
    "entries = glob.glob(\"resumes_txt/*\")\n",
    "\n",
    "for entry in entries:\n",
    "    doc_type = os.path.splitext(os.path.basename(entry))[0]\n",
    "\n",
    "    if os.path.isdir(entry):\n",
    "        # Load all .md files from the folder\n",
    "        loader = DirectoryLoader(\n",
    "            path=entry,\n",
    "            glob=\"**/*.md\",\n",
    "            loader_cls=TextLoader,\n",
    "            loader_kwargs=text_loader_kwargs\n",
    "        )\n",
    "        folder_docs = loader.load()\n",
    "    elif os.path.isfile(entry) and entry.endswith(\".txt\"):\n",
    "        # Load a single .txt file\n",
    "        loader = TextLoader(entry, **text_loader_kwargs)\n",
    "        folder_docs = loader.load()\n",
    "    else:\n",
    "        continue  # skip unsupported file types\n",
    "\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Summary\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2921c61c-d155-48d7-ba5c-db2d40f63700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 3 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d0daa3-1807-4f6c-898a-3a2d943e7d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34060326-426b-4301-875e-6aa2394ca396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15740\\2669631352.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "retriever = vectorstore.as_retriever()\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "684afe6c-9140-48e6-8b80-e6caee1d1346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rishi Kora is an aspiring LLM Engineer who recently graduated with a Master's degree in Data Science from the University of Essex. He specializes in LLM engineering and has experience building end-to-end transformer pipelines, implementing RAG systems, and deploying LLMs. He holds a UK Post-Study Work Visa valid through 2026 and is actively seeking entry-level LLM Engineering roles in the UK. Rishi is proficient in several programming languages and tools, including Python, PyTorch, Hugging Face, and AWS SageMaker.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Rishi Kora\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49032a83-4f9b-4f29-bf68-4d6c3539e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d343427-47f6-432c-9971-ed9c1280ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "387610f3-867c-4b9f-9cd2-7ecbccd22066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://7447609f659bf9960a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7447609f659bf9960a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b8dd3-692d-4cd6-b354-e1b75dbd7069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
